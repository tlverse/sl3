% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_glmnet.R
\docType{class}
\name{Lrnr_glmnet}
\alias{Lrnr_glmnet}
\title{GLMs with Elastic Net Regularization}
\format{\code{\link{R6Class}} object.}
\usage{
Lrnr_glmnet
}
\value{
Learner object with methods for training and prediction. See
\code{\link{Lrnr_base}} for documentation on learners.
}
\description{
This learner provides fitting procedures for elastic net models, using the
\code{glmnet} package, using \code{\link[glmnet]{cv.glmnet}} to select an
appropriate value of lambda.
}
\section{Parameters}{

\describe{
\item{\code{lambda=NULL}}{A vector of lambda values to compare}
\item{\code{type.measure="deviance"}}{The loss to use when selecting
lambda. Options documented in \code{\link[glmnet]{cv.glmnet}}.}
\item{\code{nfolds=10}}{Number of folds to use for internal
cross-validation.}
\item{\code{alpha=1}}{The elastic net parameter. 0 is Ridge Regression, 1
is Lasso. Intermediate values are a combination. Documented in
\code{\link[glmnet]{glmnet}}.}
\item{\code{nlambda=100}}{The number of lambda values to compare. Comparing
less values will speed up computation, but may decrease statistical
performance. Documented in \code{\link[glmnet]{cv.glmnet}}.}
\item{\code{use_min=TRUE}}{If TRUE, use lambda=cv_fit$lambda.min for prediction,
otherwise use lambda=cv_fit$lambda.1se.
the distinction is clarified in \code{\link[glmnet]{cv.glmnet}}.}
\item{\code{...}}{Other parameters to be passed to
\code{\link[glmnet]{cv.glmnet}} and \code{\link[glmnet]{glmnet}}.}
}
}

\section{Common Parameters}{


Individual learners have their own sets of parameters. Below is a list of shared parameters, implemented by \code{Lrnr_base}, and shared
by all learners.

\describe{
  \item{\code{covariates}}{A character vector of covariates. The learner will use this to subset the covariates for any specified task}
  \item{\code{outcome_type}}{A \code{\link{variable_type}} object used to control the outcome_type used by the learner. Overrides the task outcome_type if specified}
  \item{\code{...}}{All other parameters should be handled by the invidual learner classes. See the documentation for the learner class you're instantiating}
}
}

\seealso{
Other Learners: \code{\link{Custom_chain}},
  \code{\link{Lrnr_HarmonicReg}}, \code{\link{Lrnr_arima}},
  \code{\link{Lrnr_bartMachine}}, \code{\link{Lrnr_base}},
  \code{\link{Lrnr_bilstm}}, \code{\link{Lrnr_condensier}},
  \code{\link{Lrnr_cv}}, \code{\link{Lrnr_dbarts}},
  \code{\link{Lrnr_define_interactions}},
  \code{\link{Lrnr_expSmooth}},
  \code{\link{Lrnr_glm_fast}}, \code{\link{Lrnr_glm}},
  \code{\link{Lrnr_grf}}, \code{\link{Lrnr_h2o_grid}},
  \code{\link{Lrnr_hal9001}},
  \code{\link{Lrnr_independent_binomial}},
  \code{\link{Lrnr_lstm}}, \code{\link{Lrnr_mean}},
  \code{\link{Lrnr_nnls}}, \code{\link{Lrnr_optim}},
  \code{\link{Lrnr_pca}},
  \code{\link{Lrnr_pkg_SuperLearner}},
  \code{\link{Lrnr_randomForest}},
  \code{\link{Lrnr_ranger}}, \code{\link{Lrnr_rpart}},
  \code{\link{Lrnr_rugarch}}, \code{\link{Lrnr_sl}},
  \code{\link{Lrnr_solnp_density}},
  \code{\link{Lrnr_solnp}},
  \code{\link{Lrnr_subset_covariates}},
  \code{\link{Lrnr_svm}}, \code{\link{Lrnr_tsDyn}},
  \code{\link{Lrnr_xgboost}}, \code{\link{Pipeline}},
  \code{\link{Stack}}, \code{\link{define_h2o_X}},
  \code{\link{undocumented_learner}}
}
\keyword{data}
