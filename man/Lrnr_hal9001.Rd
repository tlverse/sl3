% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_hal9001.R
\docType{class}
\name{Lrnr_hal9001}
\alias{Lrnr_hal9001}
\title{Scalable Highly Adaptive Lasso (HAL)}
\format{
An \code{\link[R6]{R6Class}} object inheriting from
\code{\link{Lrnr_base}}.
}
\value{
A learner object inheriting from \code{\link{Lrnr_base}} with
methods for training and prediction. For a full list of learner
functionality, see the complete documentation of \code{\link{Lrnr_base}}.
}
\description{
The Highly Adaptive Lasso (HAL) is a nonparametric regression function that
has been demonstrated to optimally estimate functions with bounded (finite)
variation norm. The algorithm proceeds by first building an adaptive basis
(i.e., the HAL basis) based on indicator basis functions (or higher-order
spline basis functions) representing covariates and interactions of the
covariates up to a pre-specified degree. The fitting procedures included in
this learner use \code{\link[hal9001]{fit_hal}} from the \pkg{hal9001}
package. For details on HAL regression, consider consulting the following
\insertCite{benkeser2016hal;textual}{sl3}),
\insertCite{coyle2020hal9001-rpkg;textual}{sl3}),
\insertCite{hejazi2020hal9001-joss;textual}{sl3}).
}
\section{Parameters}{

\itemize{
\item \code{max_degree = 2}: An integer specifying the highest order of
interaction terms for which basis functions ought to be generated.
\item \code{smoothness_orders = 1}: An integer specifying the smoothness of
the basis functions. See details of \code{hal9001} package's
\code{\link[hal9001]{fit_hal}} function for more information.
\item \code{num_knots = 5}: An integer vector of length 1 or of length
\code{max_degree}, specifying the maximum number of knot points
(i.e., bins) for each covariate. If \code{num_knots} is a unit-length
vector, then the same \code{num_knots} are used for each degree. See
details of \code{hal9001} package's \code{\link[hal9001]{fit_hal}}
function for more information.
\item \code{fit_control}: List of arguments, including those specified in
\code{\link[hal9001]{fit_hal}}'s  \code{fit_control} documentation, and
any additional arguments to be passed to \code{\link[glmnet]{cv.glmnet}}
or \code{\link[glmnet]{glmnet}}. See the \code{hal9001} package
\code{\link[hal9001]{fit_hal}} function fdocumentation or more
information.
\item \code{...}: Other parameters passed to \code{\link[hal9001]{fit_hal}}
and additional arguments defined in \code{\link{Lrnr_base}}, such as
\code{params} like \code{formula}.
}
}

\examples{
data(cpp_imputed)
covs <- c("apgar1", "apgar5", "parity", "gagebrth", "mage", "meducyrs")
task <- sl3_Task$new(cpp_imputed, covariates = covs, outcome = "haz")

# instantiate with max 2-way interactions, 0-order splines, and binning
# (i.e., num_knots) that decreases with increasing interaction degree
hal_lrnr <- Lrnr_hal9001$new(max_degree = 2, num_knots = c(5, 3))
hal_fit <- hal_lrnr$train(task)
hal_preds <- hal_fit$predict()
}
\seealso{
Other Learners: 
\code{\link{Custom_chain}},
\code{\link{Lrnr_HarmonicReg}},
\code{\link{Lrnr_arima}},
\code{\link{Lrnr_bartMachine}},
\code{\link{Lrnr_base}},
\code{\link{Lrnr_bayesglm}},
\code{\link{Lrnr_caret}},
\code{\link{Lrnr_cv}},
\code{\link{Lrnr_cv_selector}},
\code{\link{Lrnr_dbarts}},
\code{\link{Lrnr_define_interactions}},
\code{\link{Lrnr_density_discretize}},
\code{\link{Lrnr_density_hse}},
\code{\link{Lrnr_density_semiparametric}},
\code{\link{Lrnr_earth}},
\code{\link{Lrnr_expSmooth}},
\code{\link{Lrnr_ga}},
\code{\link{Lrnr_gam}},
\code{\link{Lrnr_gbm}},
\code{\link{Lrnr_glm}},
\code{\link{Lrnr_glm_fast}},
\code{\link{Lrnr_glm_semiparametric}},
\code{\link{Lrnr_glmnet}},
\code{\link{Lrnr_glmtree}},
\code{\link{Lrnr_grf}},
\code{\link{Lrnr_grfcate}},
\code{\link{Lrnr_gru_keras}},
\code{\link{Lrnr_gts}},
\code{\link{Lrnr_h2o_grid}},
\code{\link{Lrnr_haldensify}},
\code{\link{Lrnr_hts}},
\code{\link{Lrnr_independent_binomial}},
\code{\link{Lrnr_lightgbm}},
\code{\link{Lrnr_lstm_keras}},
\code{\link{Lrnr_mean}},
\code{\link{Lrnr_multiple_ts}},
\code{\link{Lrnr_multivariate}},
\code{\link{Lrnr_nnet}},
\code{\link{Lrnr_nnls}},
\code{\link{Lrnr_optim}},
\code{\link{Lrnr_pca}},
\code{\link{Lrnr_pkg_SuperLearner}},
\code{\link{Lrnr_polspline}},
\code{\link{Lrnr_pooled_hazards}},
\code{\link{Lrnr_randomForest}},
\code{\link{Lrnr_ranger}},
\code{\link{Lrnr_revere_task}},
\code{\link{Lrnr_rpart}},
\code{\link{Lrnr_rugarch}},
\code{\link{Lrnr_screener_augment}},
\code{\link{Lrnr_screener_coefs}},
\code{\link{Lrnr_screener_correlation}},
\code{\link{Lrnr_screener_importance}},
\code{\link{Lrnr_sl}},
\code{\link{Lrnr_solnp}},
\code{\link{Lrnr_solnp_density}},
\code{\link{Lrnr_stratified}},
\code{\link{Lrnr_subset_covariates}},
\code{\link{Lrnr_svm}},
\code{\link{Lrnr_tsDyn}},
\code{\link{Lrnr_ts_weights}},
\code{\link{Lrnr_xgboost}},
\code{\link{Pipeline}},
\code{\link{Stack}},
\code{\link{define_h2o_X}()},
\code{\link{undocumented_learner}}
}
\concept{Learners}
\keyword{data}
