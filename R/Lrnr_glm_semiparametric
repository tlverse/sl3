#' Semiparametric Generalized Linear Models
#'
#' This learner provides fitting procedures for semiparametric generalized linear models using a user-given baseline learner and
#' \code{\link[stats]{glm.fit}}.
#'
#' @docType class
#'
#' @importFrom R6 R6Class
#' @importFrom stats glm predict family
#'
#' @export
#'
#' @keywords data
#'
#' @return Learner object with methods for training and prediction. See
#'  \code{\link{Lrnr_base}} for documentation on learners.
#'
#' @format \code{\link{R6Class}} object.
#'
#' @family Learners
#'
#' @section Parameters:
#' \describe{
#'   \item{\code{formula_sp}}{ A \code{formula} object specifying the parametric component of the semiparametric model.}
#'   \item{\code{lrnr_baseline}}{A baseline learner for estimation of the nonparametric component.}
#'   \item{\code{interaction_variable}}{A interaction variable to multiply with the design matrix generated by \code{formula_sp}. If NULL then the interaction variable is treated as the value 1.
#'   In many applications, this represents a binary treatment variable `A`.}
#'   \item{\code{family}}{A family object whose link function specifies the type of semiparametric model (e.g. partially-linear least-squares (\code{gaussian}), partially-linear logistic regression (\code{binomial}), partially-linear relative-risk regression (\code{poisson}) }
#'   \item{\code{append_interaction_matrix}}{Whether to \code{lrnr_baseline} should be fit on `cbind(task$X,A*V)` where `A` is the interaction variable and `V` is the design matrix obtained from \code{formula_sp}.
#'   Note, if `append_interaction_matrix = TRUE`, the resulting estimator will be projected onto the semiparametric model using \code{glm.fit}.
#'   If this is FALSE and \code{interaction_variable} is binary then the semiparametric model is learned by stratifying on \code{interaction_variable}.
#'   Specifically, if FALSE, \code{lrnr_baseline} is used to estimate `E[Y|A=0,W]` by subsetting to only observations with `A` = 0.
#'   In the binary case, setting `append_interaction_matrix = TRUE` allows one to pool the learning across treatment arms and allows additive models to perform well.  }
#'   \item{\code{return_matrix_predictions}}{Only used if \code{interaction_variable} is binary. Whether to return a matrix output with three columns being `E[Y|A=0,W], E[Y|A=1,W], E[Y|A,W]`.}
#'
#' }
#'
#
Lrnr_glm_semiparametric <- R6Class(
  classname = "Lrnr_glm_semiparametric", inherit = Lrnr_base,
  portable = TRUE, class = TRUE,
  public = list(
    initialize = function(formula_sp, lrnr_baseline, interaction_variable = "A", family = NULL, append_interaction_matrix = TRUE, return_matrix_predictions = F, ...) {
      params <- args_to_list()
      super$initialize(params = params, ...)
    }
  ),

  private = list(
    .properties = c("continuous", "binomial", "semiparametric", "weights"),

    .train = function(task) {

      args <- self$params
      append_interaction_matrix <- args$append_interaction_matrix
      outcome_type <- self$get_outcome_type(task)
      trt <- args$interaction_variable
      if(is.null(trt)) {
        A <- rep(1, task$nrow)
      } else {
        A <- unlist(task$get_data(,trt))
      }
      if(!all(A %in% c(0,1)) && !is.null(trt)) {
        binary <- FALSE
      } else {
        binary <- TRUE
      }
      family <- args$family
      lrnr_baseline <- args$lrnr_baseline
      formula <- args$formula_sp
      if (is.null(family)) {
        family <- outcome_type$glm_family(return_object = TRUE)
      }
      # Interaction design matrix
      Y <- task$Y
      V <- model.matrix(formula, task$data)
      colnames(V) <- paste0("V", 1:ncol(V))

      covariates <- setdiff(task$nodes$covariates, trt)

      if(!append_interaction_matrix && binary) {
        task_baseline <- task$next_in_chain(covariates = covariates)
        lrnr_baseline <- lrnr_baseline$train(task_baseline[A==0])
        Q0 <- lrnr_baseline$predict(task_baseline)
        beta <- suppressWarnings(coef(glm.fit(A*V, Y, offset = family$linkfun(Q0), intercept = F, weights = task$weights, family = family)))
        Q1 <- family$linkinv(family$linkfun(Q0) + V%*%beta)
        Q <- ifelse(A==1, Q1, Q0)
      } else {

        covariates <- setdiff(task$nodes$covariates, trt)

        if(append_interaction_matrix) {
          AV <- as.data.table(A*V)
          X <- cbind(task$X[,covariates, with = F], AV)
          X0 <- cbind(task$X[,covariates, with = F], 0*V)
        } else {
          X <- cbind(task$X[,covariates, with = F], A)
          X0 <- cbind(task$X[,covariates, with = F], A*0)
        }


        column_names <- task$add_columns(X)
        task_baseline <- task$next_in_chain(covariates = colnames(X), column_names = column_names )

        column_names <- task$add_columns(X0)
        task_baseline0 <- task$next_in_chain(covariates = colnames(X0), column_names = column_names )

        lrnr_baseline <- lrnr_baseline$train(task_baseline)
        Q <- lrnr_baseline$predict(task_baseline)
        Q0 <- lrnr_baseline$predict(task_baseline0)
        # Project onto model

        beta <- suppressWarnings(coef(glm.fit(A*V, Q, offset = family$linkfun(Q0), intercept = F, weights = task$weights, family = family)))

      }

       fit_object = list(beta = beta, lrnr_baseline = lrnr_baseline, covariates = covariates, family = family, formula = formula,
                         append_interaction_matrix = append_interaction_matrix, binary = binary, task_baseline = task_baseline)
      return(fit_object)
    },
    .predict = function(task) {
      fit_object <- self$fit_object
      append_interaction_matrix <- fit_object$append_interaction_matrix
      binary <- fit_object$binary
      beta <- fit_object$beta
      lrnr_baseline <- fit_object$lrnr_baseline
      covariates <- fit_object$covariates
      family <- fit_object$family
      formula <- fit_object$formula

      trt <- self$params$interaction_variable
      if(is.null(trt)) {
        A <- rep(1, task$nrow)
      } else {
        A <- unlist(task$get_data(,trt))
      }
      V <- model.matrix(formula, task$data)
      colnames(V) <- paste0("V", 1:ncol(V))


      if(!append_interaction_matrix && binary) {
        task_baseline <- task$next_in_chain(covariates = covariates)
        Q0 <- lrnr_baseline$predict(task_baseline)
      } else {
        if(append_interaction_matrix) {
          X0 <- cbind(task$X[,covariates, with = F], 0*V)
        } else {
          X0 <- cbind(task$X[,covariates, with = F], 0)
        }
        column_names <- task$add_columns(X0)
        task_baseline0 <- task$next_in_chain(covariates = colnames(X0), column_names = column_names )
        Q0 <-  lrnr_baseline$predict(task_baseline0)
      }

      Q1 <- family$linkinv(family$linkfun(Q0) + V%*%beta)
      Q <- family$linkinv(family$linkfun(Q0) + A*V%*%beta)
      if(self$params$return_matrix_predictions && binary) {
        predictions <- cbind(Q0,Q1,Q)
        colnames(predictions) <- c("A=0", "A=1", "A")
        predictions <- sl3::pack_predictions(predictions)
      } else {
        predictions <- Q
      }


      return(predictions)
    }
  )
)
