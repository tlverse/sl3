% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_caret.R
\docType{class}
\name{Lrnr_caret}
\alias{Lrnr_caret}
\title{Caret (Classification and Regression) Training}
\format{
An \code{\link[R6]{R6Class}} object inheriting from
\code{\link{Lrnr_base}}.
}
\value{
A learner object inheriting from \code{\link{Lrnr_base}} with
methods for training and prediction. For a full list of learner
functionality, see the complete documentation of \code{\link{Lrnr_base}}.
}
\description{
This learner uses the \pkg{caret} package's \code{\link[caret]{train}}
function to automatically tune a predictive model. It does this by defining
a grid of model-specific tuning parameters; fitting the model according to
each tuning parameter specification, to establish a set of models fits;
calculating a resampling-based performance measure each variation; and
then selecting the model with the best performance.
}
\section{Parameters}{

\itemize{
\item \code{method}: A string specifying which \pkg{caret} classification or
regression model to use. Possible models can be found using
\code{names(caret::getModelInfo())}. Information about a model,
including the parameters that are tuned, can be found using
\code{caret::modelLookup()}, e.g.,
\code{caret::modelLookup("xgbLinear")}. Consult the \code{caret}
package's documentation on \code{\link[caret]{train}} for more details.
\item \code{metric = NULL}: An optional string specifying the summary metric to
be used to select the optimal model. If not specified, it will be set
to "RMSE" for continuous outcomes and "Accuracy" for categorical and
binary outcomes. Other options include "MAE", "Kappa", "Rsquared" and
"logLoss". Regression models are defined when \code{metric} is set as
"RMSE", "logLoss", "Rsquared", or "MAE". Classification models are
defined when \code{metric} is set as "Accuracy" or "Kappa". Custom
performance metrics can also be used. Consult the \code{caret} package's
\code{\link[caret]{train}} documentation for more details.
\item \code{trControl = list(method = "cv", number = 10)}: A list for specifying
the arguments for \code{\link[caret]{trainControl}} object. If not
specified, it will consider "cv" with 10 folds as the resampling method,
instead of \code{caret}'s default resampling method, "boot". For a
detailed description, consult the \code{caret} package's documentation
for \code{\link[caret]{train}} and \code{\link[caret]{trainControl}}.
\item \code{factor_binary_outcome = TRUE}: Logical indicating whether a binary
outcome should be defined as a factor instead of a numeric. This
only needs to be modified to \code{FALSE} in the following uncommon
instance: when \code{metric} is specified by the user, \code{metric}
defines a regression model, and the task's outcome is binary. Note that
\code{\link[caret]{train}} could throw warnings/errors when regression
models are considered for binary outcomes; this argument should only
be modified by advanced users in niche settings.
\item \code{...}: Other parameters passed to \code{\link[caret]{train}} and
additional arguments defined in \code{\link{Lrnr_base}}, such as
\code{params} like \code{formula}.
}
}

\examples{
\dontrun{
data(cpp_imputed)
covs <- c("apgar1", "apgar5", "parity", "gagebrth", "mage", "meducyrs")
task <- sl3_Task$new(cpp_imputed, covariates = covs, outcome = "haz")
autotuned_RF_lrnr <- Lrnr_caret$new(method = "rf")
set.seed(693)
autotuned_RF_fit <- autotuned_RF_lrnr$train(task)
autotuned_RF_predictions <- autotuned_RF_fit$predict()
}
}
\seealso{
Other Learners: 
\code{\link{Custom_chain}},
\code{\link{Lrnr_HarmonicReg}},
\code{\link{Lrnr_arima}},
\code{\link{Lrnr_bartMachine}},
\code{\link{Lrnr_base}},
\code{\link{Lrnr_bayesglm}},
\code{\link{Lrnr_cv}},
\code{\link{Lrnr_cv_selector}},
\code{\link{Lrnr_dbarts}},
\code{\link{Lrnr_define_interactions}},
\code{\link{Lrnr_density_discretize}},
\code{\link{Lrnr_density_hse}},
\code{\link{Lrnr_density_semiparametric}},
\code{\link{Lrnr_earth}},
\code{\link{Lrnr_expSmooth}},
\code{\link{Lrnr_ga}},
\code{\link{Lrnr_gam}},
\code{\link{Lrnr_gbm}},
\code{\link{Lrnr_glm}},
\code{\link{Lrnr_glm_fast}},
\code{\link{Lrnr_glm_semiparametric}},
\code{\link{Lrnr_glmnet}},
\code{\link{Lrnr_glmtree}},
\code{\link{Lrnr_grf}},
\code{\link{Lrnr_grfcate}},
\code{\link{Lrnr_gru_keras}},
\code{\link{Lrnr_h2o_grid}},
\code{\link{Lrnr_hal9001}},
\code{\link{Lrnr_haldensify}},
\code{\link{Lrnr_independent_binomial}},
\code{\link{Lrnr_lightgbm}},
\code{\link{Lrnr_lstm_keras}},
\code{\link{Lrnr_mean}},
\code{\link{Lrnr_multiple_ts}},
\code{\link{Lrnr_multivariate}},
\code{\link{Lrnr_nnet}},
\code{\link{Lrnr_nnls}},
\code{\link{Lrnr_optim}},
\code{\link{Lrnr_pca}},
\code{\link{Lrnr_pkg_SuperLearner}},
\code{\link{Lrnr_polspline}},
\code{\link{Lrnr_pooled_hazards}},
\code{\link{Lrnr_randomForest}},
\code{\link{Lrnr_ranger}},
\code{\link{Lrnr_revere_task}},
\code{\link{Lrnr_rpart}},
\code{\link{Lrnr_rugarch}},
\code{\link{Lrnr_screener_augment}},
\code{\link{Lrnr_screener_coefs}},
\code{\link{Lrnr_screener_correlation}},
\code{\link{Lrnr_screener_importance}},
\code{\link{Lrnr_sl}},
\code{\link{Lrnr_solnp}},
\code{\link{Lrnr_solnp_density}},
\code{\link{Lrnr_stratified}},
\code{\link{Lrnr_subset_covariates}},
\code{\link{Lrnr_svm}},
\code{\link{Lrnr_tsDyn}},
\code{\link{Lrnr_ts_weights}},
\code{\link{Lrnr_xgboost}},
\code{\link{Pipeline}},
\code{\link{Stack}},
\code{\link{define_h2o_X}()},
\code{\link{undocumented_learner}}
}
\concept{Learners}
\keyword{data}
