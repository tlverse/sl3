% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_hal9001.R
\docType{class}
\name{Lrnr_hal9001}
\alias{Lrnr_hal9001}
\title{The Scalable Highly Adaptive Lasso}
\format{\code{\link{R6Class}} object.}
\usage{
Lrnr_hal9001
}
\value{
Learner object with methods for training and prediction. See
\code{\link{Lrnr_base}} for documentation on learners.
}
\description{
The Highly Adaptive Lasso is an estimation procedure that generates a design
matrix consisting of basis functions corresponding to covariates and
interactions of covariates and fits Lasso regression to this (usually) very
wide matrix, recovering a nonparametric functional form that describes the
target prediction function as a composition of subset functions with finite
variation norm. This implementation uses the \code{hal9001} R package, which
provides both a custom implementation (based on the \code{origami} package)
of the CV-Lasso as well the standard call to \code{cv.glmnet} from the
\code{glmnet} package.
}
\section{Parameters}{

\describe{
\item{\code{max_degree=3}}{ The highest order of interaction
terms for which the basis functions ought to be generated. The default
corresponds to generating basis functions up to all 3-way interactions of
covariates in the input matrix, matching the default in \pkg{hal9001}.
}
\item{\code{fit_type="glmnet"}}{The specific routine to be called when
fitting the Lasso regression in a cross-validated manner. Choosing the
\code{"glmnet"} option calls either \code{\link[glmnet]{cv.glmnet}} or
\code{\link[glmnet]{glmnet}}.
}
\item{\code{n_folds=10}}{Integer for the number of folds to be used
when splitting the data for cross-validation. This defaults to 10 as this
is the convention for V-fold cross-validation.
}
\item{\code{use_min=TRUE}}{Determines which lambda is selected from
\code{\link[glmnet]{cv.glmnet}}. \code{TRUE} corresponds to
\code{"lambda.min"} and \code{FALSE} corresponds to \code{"lambda.1se"}.
}
\item{\code{reduce_basis=NULL}}{A \code{numeric} value bounded in the open
interval (0,1) indicating the minimum proportion of ones in a basis
function column needed for the basis function to be included in the
procedure to fit the Lasso. Any basis functions with a lower proportion of
1's than the specified cutoff will be removed. This argument defaults to
\code{NULL}, in which case all basis functions are used in the Lasso stage
of HAL.
}
\item{\code{return_lasso=TRUE}}{A \code{logical} indicating whether or not
to return the \code{\link[glmnet]{glmnet}} fit of the Lasso model.
}
\item{\code{return_x_basis=FALSE}}{A \code{logical} indicating whether or
not to return the matrix of (possibly reduced) basis functions used in the
HAL Lasso fit.
}
\item{\code{basis_list=NULL}}{The full set of basis functions generated
from the input data (from \code{\link[hal9001]{enumerate_basis}}). The
dimensionality of this structure is roughly (n * 2^(d - 1)), where n is
the number of observations and d is the number of columns in the input.
}
\item{\code{cv_select=TRUE}}{A \code{logical} specifying whether the array
of values specified should be passed to \code{\link[glmnet]{cv.glmnet}} in
order to pick the optimal value (based on cross-validation) (when set to
\code{TRUE}) or to simply fit along the sequence of values (or a single
value) using \code{\link[glmnet]{glmnet}} (when set to \code{FALSE}).
}
\item{\code{...}}{Other parameters passed directly to
\code{\link[hal9001]{fit_hal}}. See its documentation for details.
}
}
}

\seealso{
<<<<<<< HEAD
Other Learners: \code{\link{Custom_chain}},
  \code{\link{Lrnr_HarmonicReg}}, \code{\link{Lrnr_arima}},
  \code{\link{Lrnr_bartMachine}}, \code{\link{Lrnr_base}},
  \code{\link{Lrnr_bilstm}}, \code{\link{Lrnr_caret}},
  \code{\link{Lrnr_condensier}}, \code{\link{Lrnr_cv}},
  \code{\link{Lrnr_dbarts}},
  \code{\link{Lrnr_define_interactions}},
  \code{\link{Lrnr_density_discretize}},
  \code{\link{Lrnr_density_hse}},
  \code{\link{Lrnr_density_semiparametric}},
  \code{\link{Lrnr_earth}}, \code{\link{Lrnr_expSmooth}},
  \code{\link{Lrnr_gam}}, \code{\link{Lrnr_gbm}},
  \code{\link{Lrnr_glm_fast}}, \code{\link{Lrnr_glmnet}},
  \code{\link{Lrnr_glm}}, \code{\link{Lrnr_grf}},
  \code{\link{Lrnr_h2o_grid}},
  \code{\link{Lrnr_haldensify}},
  \code{\link{Lrnr_independent_binomial}},
  \code{\link{Lrnr_lstm}}, \code{\link{Lrnr_mean}},
  \code{\link{Lrnr_multivariate}}, \code{\link{Lrnr_nnls}},
  \code{\link{Lrnr_optim}}, \code{\link{Lrnr_pca}},
  \code{\link{Lrnr_pkg_SuperLearner}},
  \code{\link{Lrnr_polspline}},
  \code{\link{Lrnr_pooled_hazards}},
  \code{\link{Lrnr_randomForest}},
  \code{\link{Lrnr_ranger}},
  \code{\link{Lrnr_revere_task}}, \code{\link{Lrnr_rfcde}},
  \code{\link{Lrnr_rpart}}, \code{\link{Lrnr_rugarch}},
  \code{\link{Lrnr_screener_corP}},
  \code{\link{Lrnr_screener_corRank}},
  \code{\link{Lrnr_screener_randomForest}},
  \code{\link{Lrnr_sl}}, \code{\link{Lrnr_solnp_density}},
  \code{\link{Lrnr_solnp}}, \code{\link{Lrnr_stratified}},
  \code{\link{Lrnr_subset_covariates}},
  \code{\link{Lrnr_svm}}, \code{\link{Lrnr_tsDyn}},
  \code{\link{Lrnr_xgboost}}, \code{\link{Pipeline}},
  \code{\link{Stack}}, \code{\link{define_h2o_X}},
  \code{\link{undocumented_learner}}
=======
Other Learners: 
\code{\link{Custom_chain}},
\code{\link{Lrnr_HarmonicReg}},
\code{\link{Lrnr_arima}},
\code{\link{Lrnr_bartMachine}},
\code{\link{Lrnr_base}},
\code{\link{Lrnr_bilstm}},
\code{\link{Lrnr_bound}},
\code{\link{Lrnr_caret}},
\code{\link{Lrnr_condensier}},
\code{\link{Lrnr_cv_selector}},
\code{\link{Lrnr_cv}},
\code{\link{Lrnr_dbarts}},
\code{\link{Lrnr_define_interactions}},
\code{\link{Lrnr_density_discretize}},
\code{\link{Lrnr_density_hse}},
\code{\link{Lrnr_density_semiparametric}},
\code{\link{Lrnr_earth}},
\code{\link{Lrnr_expSmooth}},
\code{\link{Lrnr_gam}},
\code{\link{Lrnr_gbm}},
\code{\link{Lrnr_glm_fast}},
\code{\link{Lrnr_glmnet}},
\code{\link{Lrnr_glm}},
\code{\link{Lrnr_grf}},
\code{\link{Lrnr_h2o_grid}},
\code{\link{Lrnr_haldensify}},
\code{\link{Lrnr_independent_binomial}},
\code{\link{Lrnr_lstm}},
\code{\link{Lrnr_mean}},
\code{\link{Lrnr_multivariate}},
\code{\link{Lrnr_nnls}},
\code{\link{Lrnr_optim}},
\code{\link{Lrnr_pca}},
\code{\link{Lrnr_pkg_SuperLearner}},
\code{\link{Lrnr_polspline}},
\code{\link{Lrnr_pooled_hazards}},
\code{\link{Lrnr_randomForest}},
\code{\link{Lrnr_ranger}},
\code{\link{Lrnr_revere_task}},
\code{\link{Lrnr_rfcde}},
\code{\link{Lrnr_rpart}},
\code{\link{Lrnr_rugarch}},
\code{\link{Lrnr_screener_corP}},
\code{\link{Lrnr_screener_corRank}},
\code{\link{Lrnr_screener_randomForest}},
\code{\link{Lrnr_sl}},
\code{\link{Lrnr_solnp_density}},
\code{\link{Lrnr_solnp}},
\code{\link{Lrnr_stratified}},
\code{\link{Lrnr_subset_covariates}},
\code{\link{Lrnr_svm}},
\code{\link{Lrnr_tsDyn}},
\code{\link{Lrnr_xgboost}},
\code{\link{Pipeline}},
\code{\link{Stack}},
\code{\link{define_h2o_X}()},
\code{\link{undocumented_learner}}
>>>>>>> 63d08007057d111e9839e207e70488ebc006f5ad
}
\concept{Learners}
\keyword{data}
\section{Super class}{
\code{\link[sl3:Lrnr_base]{sl3::Lrnr_base}} -> \code{Lrnr_hal9001}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{Lrnr_hal9001$new()}}
\item \href{#method-clone}{\code{Lrnr_hal9001$clone()}}
}
}
\if{html}{
\out{<details ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="assert_trained">}\href{../../sl3/html/Lrnr_base.html#method-assert_trained}{\code{sl3::Lrnr_base$assert_trained()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="base_chain">}\href{../../sl3/html/Lrnr_base.html#method-base_chain}{\code{sl3::Lrnr_base$base_chain()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="base_predict">}\href{../../sl3/html/Lrnr_base.html#method-base_predict}{\code{sl3::Lrnr_base$base_predict()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="base_train">}\href{../../sl3/html/Lrnr_base.html#method-base_train}{\code{sl3::Lrnr_base$base_train()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="chain">}\href{../../sl3/html/Lrnr_base.html#method-chain}{\code{sl3::Lrnr_base$chain()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="custom_chain">}\href{../../sl3/html/Lrnr_base.html#method-custom_chain}{\code{sl3::Lrnr_base$custom_chain()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="get_outcome_range">}\href{../../sl3/html/Lrnr_base.html#method-get_outcome_range}{\code{sl3::Lrnr_base$get_outcome_range()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="get_outcome_type">}\href{../../sl3/html/Lrnr_base.html#method-get_outcome_type}{\code{sl3::Lrnr_base$get_outcome_type()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="predict">}\href{../../sl3/html/Lrnr_base.html#method-predict}{\code{sl3::Lrnr_base$predict()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="predict_fold">}\href{../../sl3/html/Lrnr_base.html#method-predict_fold}{\code{sl3::Lrnr_base$predict_fold()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="print">}\href{../../sl3/html/Lrnr_base.html#method-print}{\code{sl3::Lrnr_base$print()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="sample">}\href{../../sl3/html/Lrnr_base.html#method-sample}{\code{sl3::Lrnr_base$sample()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="set_train">}\href{../../sl3/html/Lrnr_base.html#method-set_train}{\code{sl3::Lrnr_base$set_train()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="subset_covariates">}\href{../../sl3/html/Lrnr_base.html#method-subset_covariates}{\code{sl3::Lrnr_base$subset_covariates()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="train">}\href{../../sl3/html/Lrnr_base.html#method-train}{\code{sl3::Lrnr_base$train()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="train_sublearners">}\href{../../sl3/html/Lrnr_base.html#method-train_sublearners}{\code{sl3::Lrnr_base$train_sublearners()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\subsection{Method \code{new()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Lrnr_hal9001$new(
  max_degree = 3,
  fit_type = "glmnet",
  n_folds = 10,
  use_min = TRUE,
  reduce_basis = NULL,
  return_lasso = TRUE,
  return_x_basis = FALSE,
  basis_list = NULL,
  cv_select = TRUE,
  ...
)}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Lrnr_hal9001$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
