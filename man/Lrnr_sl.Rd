% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_sl.R
\docType{class}
\name{Lrnr_sl}
\alias{Lrnr_sl}
\title{The Super Learner Algorithm}
\format{
An \code{\link[R6]{R6Class}} object inheriting from
\code{\link{Lrnr_base}}.
}
\value{
A learner object inheriting from \code{\link{Lrnr_base}} with
methods for training and prediction. For a full list of learner
functionality, see the complete documentation of \code{\link{Lrnr_base}}.
}
\description{
Learner that encapsulates the Super Learner algorithm. Fits metalearner on
cross-validated predictions from learners. Then forms a pipeline with the
learners.
}
\section{Parameters}{

\itemize{
\item \code{learners}: The "library" of user-specified algorithms for the
super learner to consider as candidates.
\item \code{metalearner = "default"}: The metalearner to be fit on c
cross-validated predictions from the candidates. If \code{"default"},
the \code{\link{default_metalearner}} is used to construct a
metalearner based on the \code{outcome_type} of the training
\code{task}.
\item \code{cv_control = NULL}: Optional list of arguments that will be used
to define a specific cross-validation fold structure for fitting the
super learner. Intended for use in a nested cross-validation scheme,
such as cross-validated super learner (\code{\link{cv_sl}}) or
when \code{Lrnr_sl} is considered in the list of candidate
\code{learners} in another \code{Lrnr_sl}. Includes the arguments
listed below, and any others to be passed to
\code{\link[origami]{fold_funs}}:
\itemize{
\item \code{strata = NULL}: Discrete covariate or outcome name to
define stratified cross-validation folds. If \code{NULL} and if
\code{task$outcome_type$type} is binary or categorical, then the
default behavior is to consider stratified cross-validation, where
the strata are defined with respect to the outcome. To override
the default behavior, i.e., to not consider stratified
cross-validation when \code{strata = NULL} and
\code{task$outcome_type$type} is binary or categorical is not
\code{NULL}, set \code{strata = "none"}.
\item \code{cluster_by_id = TRUE}: Logical to specify clustered
cross-validation scheme according to \code{id} in \code{task}.
Specifically, if \code{task$nodes$id} is not \code{NULL} and if
\code{cluster_by_id = TRUE} (default) then \code{task$nodes$id}
is used to define a clustered cross-validation scheme, so
dependent units are placed together in the same training sets
and validation set. To override the default behavior, i.e., to not
consider clustered cross-validation when \code{task$nodes$id} is
not \code{NULL}, set \code{cluster_by_id = FALSE}.
\item \code{fold_fun = NULL}: A function indicating the \pkg{origami}
cross-validation scheme to use, such as
\code{\link[origami]{folds_vfold}} for V-fold cross-validation.
See \code{\link[origami]{fold_funs}} for a list of possibilities.
If \code{NULL} (default) and if other \code{cv_control} arguments
are specified, e.g., \code{V}, \code{strata} or
\code{cluster_by_id}, then the default behavior is to set
\code{fold_fun = origami::folds_vfold}.
\item \code{...}: Other arguments to be passed to \code{fold_fun}, such as
\code{V} for \code{fold_fun = folds_vfold}. See
\code{\link[origami]{fold_funs}} for a list fold-function-specific
possible arguments.
}
\item \code{keep_extra = TRUE}: Stores all sub-parts of the super learner
computation. When \code{FALSE}, the resulting object has a memory
footprint that is significantly reduced through the discarding of
intermediary data structures.
\item \code{verbose = NULL}: Whether to print \code{cv_control}-related
messages. Warnings and errors are always printed. When
\code{verbose = NULL}, verbosity specified by option
\code{sl3.verbose} will be used, and the default \code{sl3.verbose}
option is \code{FALSE}. (Note: to turn on \code{sl3.verbose} option,
set \code{options("sl3.verbose" = TRUE)}.)
\item \code{...}: Any additional parameters that can be considered by
\code{\link{Lrnr_base}}.
}
}

\examples{
\dontrun{
data(cpp_imputed)
covs <- c("apgar1", "apgar5", "parity", "gagebrth", "mage", "meducyrs")
task <- sl3_Task$new(cpp_imputed, covariates = covs, outcome = "haz")
# this is just for illustrative purposes, not intended for real applications
# of the super learner!
glm_lrn <- Lrnr_glm$new()
ranger_lrn <- Lrnr_ranger$new()
lasso_lrn <- Lrnr_glmnet$new()
eSL <- Lrnr_sl$new(learners = list(glm_lrn, ranger_lrn, lasso_lrn))
eSL_fit <- eSL$train(task)
# example with cv_control, where Lrnr_sl included as a candidate
eSL_nested5folds <- Lrnr_sl$new(
  learners = list(glm_lrn, ranger_lrn, lasso_lrn),
  cv_control = list(V = 5),
  verbose = FALSE
)
dSL <- Lrnr_sl$new(
  learners = list(glm_lrn, ranger_lrn, lasso_lrn, eSL_nested5folds),
  metalearner = Lrnr_cv_selector$new(loss_squared_error)
)
dSL_fit <- dSL$train(task)
# example with cv_control, where we use cross-validated super learner
cvSL_fit <- cv_sl(
  lrnr_sl = eSL_nested5folds, task = task, eval_fun = loss_squared_error
)
}
}
\seealso{
Other Learners: 
\code{\link{Custom_chain}},
\code{\link{Lrnr_HarmonicReg}},
\code{\link{Lrnr_arima}},
\code{\link{Lrnr_bartMachine}},
\code{\link{Lrnr_base}},
\code{\link{Lrnr_bayesglm}},
\code{\link{Lrnr_caret}},
\code{\link{Lrnr_cv}},
\code{\link{Lrnr_cv_selector}},
\code{\link{Lrnr_dbarts}},
\code{\link{Lrnr_define_interactions}},
\code{\link{Lrnr_density_discretize}},
\code{\link{Lrnr_density_hse}},
\code{\link{Lrnr_density_semiparametric}},
\code{\link{Lrnr_earth}},
\code{\link{Lrnr_expSmooth}},
\code{\link{Lrnr_ga}},
\code{\link{Lrnr_gam}},
\code{\link{Lrnr_gbm}},
\code{\link{Lrnr_glm}},
\code{\link{Lrnr_glm_fast}},
\code{\link{Lrnr_glm_semiparametric}},
\code{\link{Lrnr_glmnet}},
\code{\link{Lrnr_glmtree}},
\code{\link{Lrnr_grf}},
\code{\link{Lrnr_grfcate}},
\code{\link{Lrnr_gru_keras}},
\code{\link{Lrnr_h2o_grid}},
\code{\link{Lrnr_hal9001}},
\code{\link{Lrnr_haldensify}},
\code{\link{Lrnr_independent_binomial}},
\code{\link{Lrnr_lightgbm}},
\code{\link{Lrnr_lstm_keras}},
\code{\link{Lrnr_mean}},
\code{\link{Lrnr_multiple_ts}},
\code{\link{Lrnr_multivariate}},
\code{\link{Lrnr_nnet}},
\code{\link{Lrnr_nnls}},
\code{\link{Lrnr_optim}},
\code{\link{Lrnr_pca}},
\code{\link{Lrnr_pkg_SuperLearner}},
\code{\link{Lrnr_polspline}},
\code{\link{Lrnr_pooled_hazards}},
\code{\link{Lrnr_randomForest}},
\code{\link{Lrnr_ranger}},
\code{\link{Lrnr_revere_task}},
\code{\link{Lrnr_rpart}},
\code{\link{Lrnr_rugarch}},
\code{\link{Lrnr_screener_augment}},
\code{\link{Lrnr_screener_coefs}},
\code{\link{Lrnr_screener_correlation}},
\code{\link{Lrnr_screener_importance}},
\code{\link{Lrnr_solnp}},
\code{\link{Lrnr_solnp_density}},
\code{\link{Lrnr_stratified}},
\code{\link{Lrnr_subset_covariates}},
\code{\link{Lrnr_svm}},
\code{\link{Lrnr_tsDyn}},
\code{\link{Lrnr_ts_weights}},
\code{\link{Lrnr_xgboost}},
\code{\link{Pipeline}},
\code{\link{Stack}},
\code{\link{define_h2o_X}()},
\code{\link{undocumented_learner}}
}
\concept{Learners}
\keyword{data}
